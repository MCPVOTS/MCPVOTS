#!/usr/bin/env python3
"""
Neural Strategy Architect for MCPVots Trading System
Advanced neural architecture search and continuous optimization for trading strategies

This system provides:
- Neural Architecture Search (NAS) for optimal strategy structures
- Reinforcement learning for strategy optimization
- Multi-objective optimization (return, risk, drawdown)
- Dynamic strategy adaptation based on market regimes
- Ensemble learning for robust performance
"""

import asyncio
import json
import logging
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Dict, List, Any, Callable, Optional, Tuple, Union
import sqlite3
import random
from enum import Enum
from collections import deque
import pickle

# Import additional ML libraries
try:
    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
    from sklearn.metrics import accuracy_score, precision_score, recall_score
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logging.warning("Scikit-learn not available - using simplified ML models")


class OptimizationObjective(Enum):
    RETURN = "return"
    SHARPE_RATIO = "sharpe_ratio"
    MAX_DRAWDOWN = "max_drawdown"
    WIN_RATE = "win_rate"
    PROFIT_FACTOR = "profit_factor"
    CALMAR_RATIO = "calmar_ratio"


class MarketRegime(Enum):
    TRENDING_UP = "trending_up"
    TRENDING_DOWN = "trending_down"
    SIDEWAYS = "sideways"
    VOLATILE = "volatile"
    LOW_VOLATILITY = "low_volatility"


@dataclass
class StrategyArchitecture:
    """Neural architecture for trading strategies"""
    architecture_id: str
    name: str
    layers: List[Dict[str, Any]]
    connections: List[Tuple[int, int]]  # (from_layer, to_layer)
    hyperparameters: Dict[str, Any]
    performance_metrics: Dict[str, float]
    complexity_score: float
    training_epochs: int
    validation_accuracy: float
    market_regime: MarketRegime
    created_at: datetime


@dataclass
class OptimizationResult:
    """Result of neural architecture optimization"""
    optimization_id: str
    original_architecture: StrategyArchitecture
    optimized_architecture: StrategyArchitecture
    performance_improvement: float
    optimization_time: float
    optimization_steps: int
    convergence_achieved: bool
    best_metrics: Dict[str, float]


class NeuralLayer:
    """Base class for neural network layers in trading strategies"""
    
    def __init__(self, layer_type: str, input_size: int, output_size: int, **kwargs):
        self.layer_type = layer_type
        self.input_size = input_size
        self.output_size = output_size
        self.parameters = kwargs
        self.performance_contribution = 0.0
    
    def forward(self, x):
        """Forward pass through the layer"""
        pass
    
    def get_complexity(self) -> float:
        """Calculate computational complexity of the layer"""
        if self.layer_type == "linear":
            return self.input_size * self.output_size
        elif self.layer_type == "lstm":
            return 4 * self.input_size * self.output_size  # 4 gates
        elif self.layer_type == "attention":
            return self.input_size * self.output_size * 3  # Q, K, V
        else:
            return self.input_size * self.output_size


class TradingNeuralNetwork(nn.Module):
    """Neural network for trading strategy decisions"""
    
    def __init__(self, architecture: StrategyArchitecture):
        super().__init__()
        self.architecture = architecture
        self.layers = nn.ModuleList()
        self.build_network()
    
    def build_network(self):
        """Build neural network from architecture specification"""
        
        for layer_spec in self.architecture.layers:
            layer_type = layer_spec["type"]
            
            if layer_type == "linear":
                layer = nn.Linear(layer_spec["input_size"], layer_spec["output_size"])
            elif layer_type == "lstm":
                layer = nn.LSTM(
                    layer_spec["input_size"], 
                    layer_spec["output_size"],
                    batch_first=True,
                    dropout=layer_spec.get("dropout", 0.1)
                )
            elif layer_type == "attention":
                layer = nn.MultiheadAttention(
                    layer_spec["embed_dim"],
                    layer_spec["num_heads"],
                    dropout=layer_spec.get("dropout", 0.1),
                    batch_first=True
                )
            elif layer_type == "dropout":
                layer = nn.Dropout(layer_spec["probability"])
            elif layer_type == "relu":
                layer = nn.ReLU()
            elif layer_type == "sigmoid":
                layer = nn.Sigmoid()
            elif layer_type == "softmax":
                layer = nn.Softmax(dim=layer_spec.get("dim", -1))
            else:
                # Default to linear layer
                layer = nn.Linear(layer_spec.get("input_size", 64), layer_spec.get("output_size", 32))
            
            self.layers.append(layer)
    
    def forward(self, x):
        """Forward pass through the network"""
        
        for i, layer in enumerate(self.layers):
            if isinstance(layer, nn.LSTM):
                x, _ = layer(x)
            elif isinstance(layer, nn.MultiheadAttention):
                x, _ = layer(x, x, x)
            else:
                x = layer(x)
        
        return x


class NeuralStrategyArchitect:
    """
    Neural Strategy Architect for automatic strategy optimization
    
    Features:
    - Neural Architecture Search (NAS) for optimal structures
    - Multi-objective optimization
    - Reinforcement learning for strategy improvement
    - Dynamic adaptation to market regimes
    - Ensemble methods for robust performance
    """
    
    def __init__(self, mcp_integration, knowledge_graph_url: str = "http://localhost:3002"):
        self.mcp = mcp_integration
        self.kg_url = knowledge_graph_url
        self.logger = self._setup_logging()
        
        # Architecture search space
        self.search_space = self._define_search_space()
        
        # Optimization state
        self.optimization_history = []
        self.best_architectures = {}
        self.ensemble_models = {}
        
        # Market regime detection
        self.regime_detector = None
        self.current_regime = MarketRegime.SIDEWAYS
        
        # Database for architecture persistence
        self.db_path = Path(__file__).parent / "neural_architectures.db"
        self._init_database()
        
        # Performance tracking
        self.performance_buffer = deque(maxlen=1000)
        self.optimization_metrics = {}
        
        self.logger.info("üß† Neural Strategy Architect initialized")
    
    def _setup_logging(self) -> logging.Logger:
        """Setup logging for neural strategy architect"""
        logger = logging.getLogger("NeuralStrategyArchitect")
        logger.setLevel(logging.INFO)
        
        handler = logging.FileHandler("neural_strategy_architect.log")
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def _init_database(self):
        """Initialize database for architecture storage"""
        
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS strategy_architectures (
                    architecture_id TEXT PRIMARY KEY,
                    name TEXT NOT NULL,
                    layers TEXT NOT NULL,
                    connections TEXT NOT NULL,
                    hyperparameters TEXT NOT NULL,
                    performance_metrics TEXT NOT NULL,
                    complexity_score REAL NOT NULL,
                    training_epochs INTEGER NOT NULL,
                    validation_accuracy REAL NOT NULL,
                    market_regime TEXT NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS optimization_results (
                    optimization_id TEXT PRIMARY KEY,
                    original_architecture_id TEXT NOT NULL,
                    optimized_architecture_id TEXT NOT NULL,
                    performance_improvement REAL NOT NULL,
                    optimization_time REAL NOT NULL,
                    optimization_steps INTEGER NOT NULL,
                    convergence_achieved BOOLEAN NOT NULL,
                    best_metrics TEXT NOT NULL,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS ensemble_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    ensemble_id TEXT NOT NULL,
                    member_architectures TEXT NOT NULL,
                    performance_metrics TEXT NOT NULL,
                    market_regime TEXT NOT NULL,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
    
    def _define_search_space(self) -> Dict:
        """Define the neural architecture search space"""
        
        return {
            "layer_types": [
                "linear", "lstm", "gru", "attention", 
                "conv1d", "dropout", "batch_norm"
            ],
            "activation_functions": [
                "relu", "tanh", "sigmoid", "leaky_relu", "elu"
            ],
            "layer_sizes": [16, 32, 64, 128, 256, 512],
            "sequence_lengths": [10, 20, 50, 100],
            "attention_heads": [2, 4, 8, 16],
            "dropout_rates": [0.0, 0.1, 0.2, 0.3, 0.5],
            "learning_rates": [0.001, 0.003, 0.01, 0.03, 0.1],
            "batch_sizes": [16, 32, 64, 128],
            "optimizers": ["adam", "sgd", "rmsprop", "adamw"],
            "loss_functions": ["mse", "mae", "huber", "quantile"],
            "regularization": [0.0, 0.001, 0.01, 0.1]
        }
    
    async def search_optimal_architecture(self, market_data: Dict, performance_targets: Dict) -> StrategyArchitecture:
        """
        Search for optimal neural architecture using NAS
        
        Args:
            market_data: Historical market data for training
            performance_targets: Target performance metrics
        """
        
        self.logger.info("üîç Starting Neural Architecture Search...")
        
        # Detect current market regime
        self.current_regime = await self._detect_market_regime(market_data)
        
        # Initialize population for evolutionary search
        population_size = 20
        population = []
        
        # Generate initial population
        for i in range(population_size):
            architecture = await self._generate_random_architecture(f"nas_gen0_{i}")
            population.append(architecture)
        
        # Evolutionary search
        generations = 10
        best_architecture = None
        best_fitness = -float('inf')
        
        for generation in range(generations):
            self.logger.info(f"üß¨ Generation {generation + 1}/{generations}")
            
            # Evaluate population
            fitness_scores = []
            for arch in population:
                fitness = await self._evaluate_architecture(arch, market_data, performance_targets)
                fitness_scores.append(fitness)
                
                if fitness > best_fitness:
                    best_fitness = fitness
                    best_architecture = arch
            
            self.logger.info(f"   Best fitness: {best_fitness:.4f}")
            
            # Selection and crossover
            if generation < generations - 1:
                population = await self._evolve_population(population, fitness_scores)
        
        # Store best architecture
        if best_architecture:
            await self._store_architecture(best_architecture)
            self.best_architectures[self.current_regime] = best_architecture
        
        self.logger.info(f"‚úÖ NAS completed. Best fitness: {best_fitness:.4f}")
        
        return best_architecture
    
    async def _generate_random_architecture(self, name: str) -> StrategyArchitecture:
        """Generate a random neural architecture"""
        
        # Random architecture parameters
        num_layers = random.randint(3, 8)
        input_size = 64  # Standard input size for market features
        
        layers = []
        current_size = input_size
        
        for i in range(num_layers):
            if i == 0:
                # Input layer
                layer_type = random.choice(["linear", "lstm"])
                output_size = random.choice(self.search_space["layer_sizes"])
                
                layers.append({
                    "type": layer_type,
                    "input_size": current_size,
                    "output_size": output_size,
                    "activation": random.choice(self.search_space["activation_functions"])
                })
                current_size = output_size
                
            elif i == num_layers - 1:
                # Output layer (3 outputs: buy, hold, sell)
                layers.append({
                    "type": "linear",
                    "input_size": current_size,
                    "output_size": 3,
                    "activation": "softmax"
                })
                
            else:
                # Hidden layers
                layer_type = random.choice(self.search_space["layer_types"][:4])  # Only main layer types
                
                if layer_type in ["dropout", "batch_norm"]:
                    # Special layers that don't change size
                    if layer_type == "dropout":
                        layers.append({
                            "type": layer_type,
                            "probability": random.choice(self.search_space["dropout_rates"])
                        })
                    else:
                        layers.append({
                            "type": layer_type,
                            "num_features": current_size
                        })
                else:
                    # Size-changing layers
                    output_size = random.choice(self.search_space["layer_sizes"])
                    
                    layer_config = {
                        "type": layer_type,
                        "input_size": current_size,
                        "output_size": output_size,
                        "activation": random.choice(self.search_space["activation_functions"])
                    }
                    
                    if layer_type == "attention":
                        layer_config["num_heads"] = random.choice(self.search_space["attention_heads"])
                        layer_config["embed_dim"] = current_size
                    
                    layers.append(layer_config)
                    current_size = output_size
        
        # Generate connections (sequential by default)
        connections = [(i, i+1) for i in range(len(layers)-1)]
        
        # Hyperparameters
        hyperparameters = {
            "learning_rate": random.choice(self.search_space["learning_rates"]),
            "batch_size": random.choice(self.search_space["batch_sizes"]),
            "optimizer": random.choice(self.search_space["optimizers"]),
            "loss_function": random.choice(self.search_space["loss_functions"]),
            "regularization": random.choice(self.search_space["regularization"]),
            "sequence_length": random.choice(self.search_space["sequence_lengths"])
        }
        
        # Calculate complexity
        complexity = sum([self._calculate_layer_complexity(layer) for layer in layers])
        
        return StrategyArchitecture(
            architecture_id=f"arch_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}",
            name=name,
            layers=layers,
            connections=connections,
            hyperparameters=hyperparameters,
            performance_metrics={},
            complexity_score=complexity,
            training_epochs=0,
            validation_accuracy=0.0,
            market_regime=self.current_regime,
            created_at=datetime.now()
        )
    
    def _calculate_layer_complexity(self, layer: Dict) -> float:
        """Calculate computational complexity of a layer"""
        
        layer_type = layer["type"]
        
        if layer_type == "linear":
            return layer["input_size"] * layer["output_size"]
        elif layer_type in ["lstm", "gru"]:
            return 4 * layer["input_size"] * layer["output_size"]  # 4 gates
        elif layer_type == "attention":
            embed_dim = layer.get("embed_dim", layer["input_size"])
            return embed_dim * embed_dim * 3  # Q, K, V projections
        elif layer_type == "conv1d":
            kernel_size = layer.get("kernel_size", 3)
            return layer["input_size"] * layer["output_size"] * kernel_size
        else:
            return 100  # Default complexity for special layers
    
    async def _evaluate_architecture(self, architecture: StrategyArchitecture, market_data: Dict, targets: Dict) -> float:
        """Evaluate architecture fitness"""
        
        try:
            # Create and train neural network
            model = TradingNeuralNetwork(architecture)
            
            # Generate synthetic training data
            X_train, y_train = self._generate_training_data(market_data, architecture.hyperparameters["sequence_length"])
            
            # Train model
            fitness = await self._train_and_evaluate(model, X_train, y_train, architecture.hyperparameters, targets)
            
            # Update architecture performance
            architecture.performance_metrics = {
                "fitness": fitness,
                "accuracy": fitness * 0.8 + 0.2,  # Simulate accuracy
                "sharpe_ratio": fitness * 2.0,
                "max_drawdown": (1 - fitness) * 0.3
            }
            
            return fitness
            
        except Exception as e:
            self.logger.error(f"Architecture evaluation failed: {e}")
            return 0.0
    
    def _generate_training_data(self, market_data: Dict, sequence_length: int) -> Tuple[torch.Tensor, torch.Tensor]:
        """Generate training data for neural network"""
        
        # Create synthetic market features
        num_samples = 1000
        num_features = 64
        
        # Generate random market-like data
        X = torch.randn(num_samples, sequence_length, num_features)
        
        # Generate labels (0=sell, 1=hold, 2=buy)
        # Simulate realistic trading decisions
        trends = torch.randn(num_samples)
        y = torch.zeros(num_samples, dtype=torch.long)
        
        y[trends > 0.5] = 2   # Buy signal
        y[trends < -0.5] = 0  # Sell signal
        y[(trends >= -0.5) & (trends <= 0.5)] = 1  # Hold signal
        
        return X, y
    
    async def _train_and_evaluate(self, model: TradingNeuralNetwork, X: torch.Tensor, y: torch.Tensor, hyperparams: Dict, targets: Dict) -> float:
        """Train and evaluate neural network"""
        
        try:
            # Setup training
            criterion = nn.CrossEntropyLoss()
            
            if hyperparams["optimizer"] == "adam":
                optimizer = optim.Adam(model.parameters(), lr=hyperparams["learning_rate"])
            elif hyperparams["optimizer"] == "sgd":
                optimizer = optim.SGD(model.parameters(), lr=hyperparams["learning_rate"])
            else:
                optimizer = optim.Adam(model.parameters(), lr=hyperparams["learning_rate"])
            
            # Split data
            split_idx = int(0.8 * len(X))
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            
            # Training loop
            epochs = 20  # Limited epochs for NAS
            model.train()
            
            for epoch in range(epochs):
                optimizer.zero_grad()
                
                # Forward pass
                outputs = model(X_train)
                loss = criterion(outputs, y_train)
                
                # Backward pass
                loss.backward()
                optimizer.step()
            
            # Evaluation
            model.eval()
            with torch.no_grad():
                val_outputs = model(X_val)
                val_predictions = torch.argmax(val_outputs, dim=1)
                accuracy = (val_predictions == y_val).float().mean().item()
            
            # Calculate fitness based on accuracy and complexity
            complexity_penalty = model.architecture.complexity_score / 10000  # Normalize
            fitness = accuracy - complexity_penalty * 0.1
            
            return max(0.0, fitness)
            
        except Exception as e:
            self.logger.error(f"Training failed: {e}")
            return 0.0
    
    async def _evolve_population(self, population: List[StrategyArchitecture], fitness_scores: List[float]) -> List[StrategyArchitecture]:
        """Evolve population using genetic operators"""
        
        # Sort by fitness
        sorted_pairs = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)
        population = [arch for arch, _ in sorted_pairs]
        
        # Keep top 50%
        elite_size = len(population) // 2
        elite = population[:elite_size]
        
        # Generate offspring
        offspring = []
        for i in range(len(population) - elite_size):
            # Select parents
            parent1 = random.choice(elite[:elite_size//2])  # Bias towards better parents
            parent2 = random.choice(elite)
            
            # Crossover
            child = await self._crossover(parent1, parent2)
            
            # Mutation
            child = await self._mutate(child)
            
            offspring.append(child)
        
        return elite + offspring
    
    async def _crossover(self, parent1: StrategyArchitecture, parent2: StrategyArchitecture) -> StrategyArchitecture:
        """Crossover two architectures"""
        
        # Take layers from both parents
        p1_layers = parent1.layers
        p2_layers = parent2.layers
        
        # Create child layers by mixing parents
        child_layers = []
        max_layers = max(len(p1_layers), len(p2_layers))
        
        for i in range(max_layers):
            if i < len(p1_layers) and i < len(p2_layers):
                # Choose layer from random parent
                layer = random.choice([p1_layers[i], p2_layers[i]])
            elif i < len(p1_layers):
                layer = p1_layers[i]
            else:
                layer = p2_layers[i]
            
            child_layers.append(layer.copy())
        
        # Mix hyperparameters
        child_hyperparams = {}
        for key in parent1.hyperparameters:
            child_hyperparams[key] = random.choice([
                parent1.hyperparameters[key], 
                parent2.hyperparameters[key]
            ])
        
        # Create child architecture
        child = StrategyArchitecture(
            architecture_id=f"child_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}",
            name=f"crossover_{parent1.name}_{parent2.name}",
            layers=child_layers,
            connections=[(i, i+1) for i in range(len(child_layers)-1)],
            hyperparameters=child_hyperparams,
            performance_metrics={},
            complexity_score=sum([self._calculate_layer_complexity(layer) for layer in child_layers]),
            training_epochs=0,
            validation_accuracy=0.0,
            market_regime=self.current_regime,
            created_at=datetime.now()
        )
        
        return child
    
    async def _mutate(self, architecture: StrategyArchitecture) -> StrategyArchitecture:
        """Mutate an architecture"""
        
        mutation_rate = 0.2
        
        # Mutate layers
        for layer in architecture.layers:
            if random.random() < mutation_rate:
                if layer["type"] in ["linear", "lstm", "gru"] and "output_size" in layer:
                    # Mutate layer size
                    layer["output_size"] = random.choice(self.search_space["layer_sizes"])
                
                if "activation" in layer:
                    # Mutate activation function
                    layer["activation"] = random.choice(self.search_space["activation_functions"])
        
        # Mutate hyperparameters
        for key in architecture.hyperparameters:
            if random.random() < mutation_rate:
                if key in self.search_space:
                    architecture.hyperparameters[key] = random.choice(self.search_space[key])
        
        # Recalculate complexity
        architecture.complexity_score = sum([self._calculate_layer_complexity(layer) for layer in architecture.layers])
        
        return architecture
    
    async def _detect_market_regime(self, market_data: Dict) -> MarketRegime:
        """Detect current market regime"""
        
        # Simple regime detection based on volatility and trend
        # In production, this would use more sophisticated methods
        
        volatility = market_data.get('volatility', 0.5)
        trend = market_data.get('trend_strength', 0.0)
        
        if volatility > 0.8:
            return MarketRegime.VOLATILE
        elif volatility < 0.2:
            return MarketRegime.LOW_VOLATILITY
        elif trend > 0.5:
            return MarketRegime.TRENDING_UP
        elif trend < -0.5:
            return MarketRegime.TRENDING_DOWN
        else:
            return MarketRegime.SIDEWAYS
    
    async def optimize_existing_strategy(self, architecture: StrategyArchitecture, market_data: Dict, objectives: List[OptimizationObjective]) -> OptimizationResult:
        """Optimize an existing strategy architecture"""
        
        self.logger.info(f"üéØ Optimizing strategy: {architecture.name}")
        
        start_time = datetime.now()
        original_architecture = architecture
        best_architecture = architecture
        best_score = 0.0
        
        # Multi-objective optimization
        optimization_steps = 50
        
        for step in range(optimization_steps):
            # Create candidate by mutation
            candidate = await self._mutate(best_architecture)
            
            # Evaluate candidate
            score = await self._evaluate_multi_objective(candidate, market_data, objectives)
            
            if score > best_score:
                best_score = score
                best_architecture = candidate
                self.logger.info(f"   Step {step}: New best score = {best_score:.4f}")
        
        optimization_time = (datetime.now() - start_time).total_seconds()
        
        # Calculate improvement
        original_score = await self._evaluate_multi_objective(original_architecture, market_data, objectives)
        improvement = (best_score - original_score) / max(original_score, 0.001)
        
        # Create optimization result
        result = OptimizationResult(
            optimization_id=f"opt_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            original_architecture=original_architecture,
            optimized_architecture=best_architecture,
            performance_improvement=improvement,
            optimization_time=optimization_time,
            optimization_steps=optimization_steps,
            convergence_achieved=True,
            best_metrics=best_architecture.performance_metrics
        )
        
        # Store results
        await self._store_optimization_result(result)
        
        self.logger.info(f"‚úÖ Optimization complete. Improvement: {improvement:.2%}")
        
        return result
    
    async def _evaluate_multi_objective(self, architecture: StrategyArchitecture, market_data: Dict, objectives: List[OptimizationObjective]) -> float:
        """Evaluate architecture against multiple objectives"""
        
        # Simulate performance metrics
        simulated_metrics = {
            OptimizationObjective.RETURN: random.uniform(0.05, 0.25),
            OptimizationObjective.SHARPE_RATIO: random.uniform(0.5, 3.0),
            OptimizationObjective.MAX_DRAWDOWN: random.uniform(0.05, 0.30),
            OptimizationObjective.WIN_RATE: random.uniform(0.45, 0.75),
            OptimizationObjective.PROFIT_FACTOR: random.uniform(1.1, 2.5),
            OptimizationObjective.CALMAR_RATIO: random.uniform(0.5, 2.0)
        }
        
        # Weight objectives equally
        total_score = 0.0
        for objective in objectives:
            if objective == OptimizationObjective.RETURN:
                score = simulated_metrics[objective] / 0.25  # Normalize to 0-1
            elif objective == OptimizationObjective.SHARPE_RATIO:
                score = min(1.0, simulated_metrics[objective] / 3.0)
            elif objective == OptimizationObjective.MAX_DRAWDOWN:
                score = 1.0 - (simulated_metrics[objective] / 0.30)  # Lower is better
            elif objective == OptimizationObjective.WIN_RATE:
                score = simulated_metrics[objective]
            elif objective == OptimizationObjective.PROFIT_FACTOR:
                score = min(1.0, (simulated_metrics[objective] - 1.0) / 1.5)
            elif objective == OptimizationObjective.CALMAR_RATIO:
                score = min(1.0, simulated_metrics[objective] / 2.0)
            else:
                score = 0.5
            
            total_score += score
        
        return total_score / len(objectives)
    
    async def create_ensemble_strategy(self, architectures: List[StrategyArchitecture], market_data: Dict) -> Dict:
        """Create ensemble strategy from multiple architectures"""
        
        self.logger.info(f"üé≠ Creating ensemble from {len(architectures)} strategies")
        
        ensemble_id = f"ensemble_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Evaluate individual architectures
        individual_performances = []
        for arch in architectures:
            performance = await self._evaluate_architecture(arch, market_data, {})
            individual_performances.append(performance)
        
        # Weight strategies by performance
        total_performance = sum(individual_performances)
        weights = [p / total_performance for p in individual_performances] if total_performance > 0 else [1/len(architectures)] * len(architectures)
        
        # Calculate ensemble metrics
        ensemble_performance = np.average(individual_performances, weights=weights)
        
        ensemble_info = {
            "ensemble_id": ensemble_id,
            "member_count": len(architectures),
            "member_architectures": [arch.architecture_id for arch in architectures],
            "weights": weights,
            "individual_performances": individual_performances,
            "ensemble_performance": ensemble_performance,
            "created_at": datetime.now().isoformat(),
            "market_regime": self.current_regime.value
        }
        
        # Store ensemble
        self.ensemble_models[ensemble_id] = ensemble_info
        await self._store_ensemble_performance(ensemble_info)
        
        self.logger.info(f"‚úÖ Ensemble created. Performance: {ensemble_performance:.4f}")
        
        return ensemble_info
    
    async def adaptive_optimization(self, architecture: StrategyArchitecture, performance_stream: List[Dict]) -> StrategyArchitecture:
        """Continuously adapt strategy based on performance stream"""
        
        self.logger.info("üîÑ Starting adaptive optimization...")
        
        # Add performance data to buffer
        for perf in performance_stream:
            self.performance_buffer.append(perf)
        
        # Check if adaptation is needed
        if len(self.performance_buffer) < 20:
            return architecture  # Not enough data
        
        recent_performance = list(self.performance_buffer)[-20:]
        avg_recent_performance = np.mean([p.get('return', 0) for p in recent_performance])
        
        # Adaptation threshold
        adaptation_threshold = -0.02  # Adapt if performance drops below -2%
        
        if avg_recent_performance < adaptation_threshold:
            self.logger.info(f"üìâ Performance decline detected: {avg_recent_performance:.3f}")
            
            # Detect regime change
            current_market_data = recent_performance[-1].get('market_data', {})
            new_regime = await self._detect_market_regime(current_market_data)
            
            if new_regime != self.current_regime:
                self.logger.info(f"üîÑ Market regime change: {self.current_regime.value} ‚Üí {new_regime.value}")
                self.current_regime = new_regime
                
                # Get best architecture for new regime
                if new_regime in self.best_architectures:
                    adapted_architecture = self.best_architectures[new_regime]
                    self.logger.info("‚úÖ Switched to regime-specific architecture")
                    return adapted_architecture
            
            # Perform incremental optimization
            objectives = [OptimizationObjective.RETURN, OptimizationObjective.SHARPE_RATIO]
            optimization_result = await self.optimize_existing_strategy(architecture, current_market_data, objectives)
            
            return optimization_result.optimized_architecture
        
        return architecture  # No adaptation needed
    
    async def _store_architecture(self, architecture: StrategyArchitecture):
        """Store architecture in database"""
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO strategy_architectures 
                    (architecture_id, name, layers, connections, hyperparameters,
                     performance_metrics, complexity_score, training_epochs,
                     validation_accuracy, market_regime)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    architecture.architecture_id,
                    architecture.name,
                    json.dumps(architecture.layers),
                    json.dumps(architecture.connections),
                    json.dumps(architecture.hyperparameters),
                    json.dumps(architecture.performance_metrics),
                    architecture.complexity_score,
                    architecture.training_epochs,
                    architecture.validation_accuracy,
                    architecture.market_regime.value
                ))
                
        except Exception as e:
            self.logger.error(f"Failed to store architecture: {e}")
    
    async def _store_optimization_result(self, result: OptimizationResult):
        """Store optimization result in database"""
        
        try:
            # Store the optimized architecture first
            await self._store_architecture(result.optimized_architecture)
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT INTO optimization_results 
                    (optimization_id, original_architecture_id, optimized_architecture_id,
                     performance_improvement, optimization_time, optimization_steps,
                     convergence_achieved, best_metrics)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    result.optimization_id,
                    result.original_architecture.architecture_id,
                    result.optimized_architecture.architecture_id,
                    result.performance_improvement,
                    result.optimization_time,
                    result.optimization_steps,
                    result.convergence_achieved,
                    json.dumps(result.best_metrics)
                ))
                
        except Exception as e:
            self.logger.error(f"Failed to store optimization result: {e}")
    
    async def _store_ensemble_performance(self, ensemble_info: Dict):
        """Store ensemble performance in database"""
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT INTO ensemble_performance 
                    (ensemble_id, member_architectures, performance_metrics, market_regime)
                    VALUES (?, ?, ?, ?)
                """, (
                    ensemble_info["ensemble_id"],
                    json.dumps(ensemble_info["member_architectures"]),
                    json.dumps({
                        "ensemble_performance": ensemble_info["ensemble_performance"],
                        "individual_performances": ensemble_info["individual_performances"],
                        "weights": ensemble_info["weights"]
                    }),
                    ensemble_info["market_regime"]
                ))
                
        except Exception as e:
            self.logger.error(f"Failed to store ensemble performance: {e}")
    
    async def get_best_architectures(self, limit: int = 10) -> List[Dict]:
        """Get best performing architectures"""
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                rows = conn.execute("""
                    SELECT architecture_id, name, performance_metrics, 
                           complexity_score, market_regime, created_at
                    FROM strategy_architectures
                    ORDER BY validation_accuracy DESC
                    LIMIT ?
                """, (limit,)).fetchall()
                
                architectures = []
                for row in rows:
                    architectures.append({
                        "architecture_id": row[0],
                        "name": row[1],
                        "performance_metrics": json.loads(row[2]) if row[2] else {},
                        "complexity_score": row[3],
                        "market_regime": row[4],
                        "created_at": row[5]
                    })
                
                return architectures
                
        except Exception as e:
            self.logger.error(f"Failed to get best architectures: {e}")
            return []
    
    async def get_optimization_history(self, limit: int = 20) -> List[Dict]:
        """Get optimization history"""
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                rows = conn.execute("""
                    SELECT optimization_id, performance_improvement, 
                           optimization_time, optimization_steps, best_metrics, timestamp
                    FROM optimization_results
                    ORDER BY timestamp DESC
                    LIMIT ?
                """, (limit,)).fetchall()
                
                history = []
                for row in rows:
                    history.append({
                        "optimization_id": row[0],
                        "performance_improvement": row[1],
                        "optimization_time": row[2],
                        "optimization_steps": row[3],
                        "best_metrics": json.loads(row[4]) if row[4] else {},
                        "timestamp": row[5]
                    })
                
                return history
                
        except Exception as e:
            self.logger.error(f"Failed to get optimization history: {e}")
            return []


# Demo function for testing
async def demo_neural_strategy_architect():
    """Demo the neural strategy architect"""
    
    print("üß† Demo: Neural Strategy Architect")
    print("=" * 60)
    
    # Mock MCP integration
    class MockMCPIntegration:
        def get_market_data(self):
            return {"symbol": "SOL/USDT", "price": 100.0}
    
    # Initialize architect
    architect = NeuralStrategyArchitect(MockMCPIntegration())
    
    # Test market data
    market_data = {
        "symbol": "SOL/USDT",
        "volatility": 0.6,
        "trend_strength": 0.3,
        "volume_profile": "high",
        "price_history": [100, 102, 101, 103, 105]
    }
    
    # Performance targets
    performance_targets = {
        "min_sharpe_ratio": 1.5,
        "max_drawdown": 0.15,
        "min_return": 0.12
    }
    
    print(f"üìä Market Data: {market_data}")
    print(f"üéØ Performance Targets: {performance_targets}")
    
    print("\nüîç Starting Neural Architecture Search...")
    
    # Search for optimal architecture
    best_architecture = await architect.search_optimal_architecture(market_data, performance_targets)
    
    print(f"‚úÖ Best Architecture Found:")
    print(f"   ID: {best_architecture.architecture_id}")
    print(f"   Layers: {len(best_architecture.layers)}")
    print(f"   Complexity: {best_architecture.complexity_score:.0f}")
    print(f"   Performance: {best_architecture.performance_metrics.get('fitness', 0):.4f}")
    
    # Optimize existing strategy
    print(f"\nüéØ Optimizing architecture...")
    objectives = [OptimizationObjective.RETURN, OptimizationObjective.SHARPE_RATIO, OptimizationObjective.MAX_DRAWDOWN]
    optimization_result = await architect.optimize_existing_strategy(best_architecture, market_data, objectives)
    
    print(f"‚úÖ Optimization Complete:")
    print(f"   Improvement: {optimization_result.performance_improvement:.2%}")
    print(f"   Time: {optimization_result.optimization_time:.2f}s")
    print(f"   Steps: {optimization_result.optimization_steps}")
    
    # Create ensemble
    print(f"\nüé≠ Creating ensemble strategy...")
    architectures = [best_architecture, optimization_result.optimized_architecture]
    
    # Generate additional architectures for ensemble
    for i in range(3):
        arch = await architect._generate_random_architecture(f"ensemble_member_{i}")
        architectures.append(arch)
    
    ensemble_info = await architect.create_ensemble_strategy(architectures, market_data)
    
    print(f"‚úÖ Ensemble Created:")
    print(f"   Members: {ensemble_info['member_count']}")
    print(f"   Performance: {ensemble_info['ensemble_performance']:.4f}")
    
    # Show best architectures
    best_architectures = await architect.get_best_architectures(5)
    print(f"\nüèÜ Top 5 Architectures:")
    for i, arch in enumerate(best_architectures, 1):
        print(f"   {i}. {arch['name']}: {arch['performance_metrics'].get('fitness', 0):.4f}")
    
    print("\nüéâ Neural Strategy Architect Demo Complete!")


if __name__ == "__main__":
    asyncio.run(demo_neural_strategy_architect())
